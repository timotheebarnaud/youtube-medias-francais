{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c3044d0",
   "metadata": {},
   "source": [
    "# Analyse des performances des médias français sur YouTube\n",
    "\n",
    "Ce notebook présente le pipeline de collecte et de traitement des données YouTube\n",
    "utilisé pour analyser la performance des chaînes de médias français.\n",
    "\n",
    "Il couvre :\n",
    "- la récupération des vidéos via l’API YouTube,\n",
    "- le filtrage des vidéos longues (< 3 minutes) ainsi d'autres fonctions indispensables.\n",
    "- le calcul des indicateurs finaux exportés dans un CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c9083e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.14.0 (tags/v3.14.0:ebf955d, Oct  7 2025, 10:15:03) [MSC v.1944 64 bit (AMD64)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B\n",
       "0  1  3\n",
       "1  2  4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Starter ready: tout est actif !\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# STARTER SCRAPING READY\n",
    "# ===============================\n",
    "\n",
    "# Modules principaux\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import sys\n",
    "from urllib.parse import urljoin\n",
    "from pprint import pprint\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import unicodedata\n",
    "import statistics\n",
    "\n",
    "# Vérifier que le kernel est bien actif\n",
    "print(f\"Python version: {sys.version}\")\n",
    "\n",
    "# Options Pandas\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.float_format', '{:,.2f}'.format)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option('display.width', 2000)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "\n",
    "# Style Seaborn\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Test rapide Pandas\n",
    "df_test = pd.DataFrame({'A':[1,2], 'B':[3,4]})\n",
    "display(df_test)\n",
    "\n",
    "print(\"✅ Starter ready: tout est actif !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eec6020",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"///////////////////////////////\"\n",
    "youtube_overrides = {\n",
    "    \"L'Express\" : \"UCp2kK3DyhpgFOdILF3BBC9A\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b6cafe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_medias = pd.read_csv(\"../data/raw/liste_medias.csv\", encoding=\"utf-8-sig\", sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903d10a8",
   "metadata": {},
   "source": [
    "## 1. Récupération des vidéos via l’API YouTube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63040fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_youtube_raw(query: str, api_key: str, max_results: int = 5):\n",
    "\n",
    "    url = \"https://www.googleapis.com/youtube/v3/search\"\n",
    "\n",
    "    params = {\n",
    "        \"part\": \"snippet\",\n",
    "        \"q\": query,\n",
    "        \"type\" : \"channel\",\n",
    "        \"maxResults\": max_results,\n",
    "        \"key\" : api_key\n",
    "    }\n",
    "    \n",
    "    page = requests.get(url, params=params)\n",
    "    \n",
    "    print(\"HTTP status code :\", page.status_code)\n",
    "    \n",
    "    if page.status_code != 200:\n",
    "        print(\"Erreur API :\", page.text)\n",
    "        return []\n",
    "    \n",
    "    data = page.json()\n",
    "    \n",
    "    return data.get(\"items\", [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c22683be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channel_subscribers(channel_id, api_key):\n",
    "\n",
    "    url = \"https://www.googleapis.com/youtube/v3/channels\"\n",
    "\n",
    "    params = {\n",
    "        \"part\" : \"statistics\",\n",
    "        \"id\" : channel_id,\n",
    "        \"key\" : api_key\n",
    "    }\n",
    "    \n",
    "    r = requests.get(url, params=params)\n",
    "\n",
    "    if r.status_code != 200:\n",
    "        return None\n",
    "    \n",
    "    data = r.json()\n",
    "    items = data.get(\"items\", [])\n",
    "    if not items:\n",
    "        return None\n",
    "\n",
    "    stats = items[0].get(\"statistics\", {})\n",
    "    subscribers_string = stats.get(\"subscriberCount\")\n",
    "\n",
    "    if subscribers_string is None or not subscribers_string.isdigit():\n",
    "        return None\n",
    "\n",
    "    return int(subscribers_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa61107a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_channel(label_name: str, api_key: str):\n",
    " \n",
    "    if label_name in youtube_overrides:\n",
    "        channel_id = youtube_overrides[label_name]\n",
    "        \n",
    "    else:\n",
    "        results = search_youtube_raw(label_name, api_key, max_results=1)\n",
    "\n",
    "        if not results:\n",
    "            return None\n",
    "\n",
    "        channel_id = results[0][\"id\"][\"channelId\"]\n",
    "\n",
    "    subscribers = get_channel_subscribers(channel_id, api_key)\n",
    "\n",
    "    return {\n",
    "        \"label_name\": label_name,\n",
    "        \"channel_id\": channel_id,\n",
    "        \"subscribers\": subscribers\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3d044b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP status code : 200\n",
      "HTTP status code : 200\n",
      "HTTP status code : 200\n",
      "HTTP status code : 200\n",
      "HTTP status code : 200\n",
      "HTTP status code : 200\n",
      "HTTP status code : 200\n",
      "HTTP status code : 200\n",
      "HTTP status code : 200\n",
      "HTTP status code : 200\n",
      "HTTP status code : 200\n",
      "HTTP status code : 200\n",
      "HTTP status code : 200\n",
      "HTTP status code : 200\n",
      "HTTP status code : 200\n",
      "HTTP status code : 200\n",
      "HTTP status code : 200\n",
      "HTTP status code : 200\n",
      "HTTP status code : 200\n",
      "HTTP status code : 200\n"
     ]
    }
   ],
   "source": [
    "channels = []\n",
    "\n",
    "for _, row in df_medias.iterrows():\n",
    "    media_name = row[\"media_name\"]\n",
    "    label_name = row[\"label_name\"]\n",
    "\n",
    "    res = resolve_channel(label_name, api_key)\n",
    "    time.sleep(2)\n",
    "\n",
    "    if res is None:\n",
    "        print(\"SKIP :\", label_name)\n",
    "        continue\n",
    "\n",
    "    channels.append({\n",
    "        \"media_name\": media_name,\n",
    "        \"label_name\": label_name,\n",
    "        \"channel_id\": res[\"channel_id\"],\n",
    "        \"subscribers\": res[\"subscribers\"]\n",
    "    })\n",
    "\n",
    "df_channels = pd.DataFrame(channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a211ab3b",
   "metadata": {},
   "source": [
    "## 2. Création des différentes fonctions pour nos indicateurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "474f0d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uploads_playlist_id(channel_id, api_key):\n",
    "\n",
    "    url = \"https://www.googleapis.com/youtube/v3/channels\"\n",
    "\n",
    "    params = {\n",
    "        \"part\": \"contentDetails\",\n",
    "        \"id\": channel_id,\n",
    "        \"key\": api_key\n",
    "    }\n",
    "\n",
    "    r = requests.get(url, params=params)\n",
    "\n",
    "    if r.status_code != 200:\n",
    "        return None\n",
    "\n",
    "    items = r.json().get(\"items\", [])\n",
    "\n",
    "    if not items:\n",
    "        return None\n",
    "\n",
    "    return items[0][\"contentDetails\"][\"relatedPlaylists\"][\"uploads\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a5e7d6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_videos_from_playlist(playlist_id, api_key, max_pages=None):\n",
    "    \n",
    "    videos = []\n",
    "    page_token = None\n",
    "    pages_fetched = 0\n",
    "\n",
    "    while True:\n",
    "        url = \"https://www.googleapis.com/youtube/v3/playlistItems\"\n",
    "        params = {\n",
    "            \"part\": \"snippet\",\n",
    "            \"playlistId\": playlist_id,\n",
    "            \"maxResults\": 50,\n",
    "            \"pageToken\": page_token,\n",
    "            \"key\": api_key\n",
    "        }\n",
    "\n",
    "        r = requests.get(url, params=params)\n",
    "        if r.status_code != 200:\n",
    "            break\n",
    "        \n",
    "        data = r.json()\n",
    "\n",
    "        for item in data.get(\"items\", []):\n",
    "            videos.append({\n",
    "                \"video_id\": item[\"snippet\"][\"resourceId\"][\"videoId\"],\n",
    "                \"published_at\": item[\"snippet\"][\"publishedAt\"]\n",
    "            })\n",
    "\n",
    "        page_token = data.get(\"nextPageToken\")\n",
    "        pages_fetched += 1\n",
    "\n",
    "        if not page_token:\n",
    "            break\n",
    "        if max_pages and pages_fetched >= max_pages:\n",
    "            break\n",
    "\n",
    "    return videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8f1d1ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_iso8601_duration_to_seconds(duration):\n",
    "\n",
    "    h = m = s = 0\n",
    "\n",
    "    if not duration:\n",
    "        return 0\n",
    "\n",
    "    if \"H\" in duration:\n",
    "        h = int(re.search(r\"(\\d+)H\", duration).group(1))\n",
    "        \n",
    "    if \"M\" in duration:\n",
    "        m = int(re.search(r\"(\\d+)M\", duration).group(1))\n",
    "\n",
    "    if \"S\" in duration:\n",
    "        s = int(re.search(r\"(\\d+)S\", duration).group(1))\n",
    "        \n",
    "    return h * 3600 + m * 60 + s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3ba27f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_durations_from_videos(video_ids, api_key):\n",
    "\n",
    "    durations = {}\n",
    "\n",
    "    for i in range(0, len(video_ids), 50):\n",
    "        chunk = video_ids[i:i+50]\n",
    "        ids_str = \",\".join(chunk)\n",
    "\n",
    "        url = \"https://www.googleapis.com/youtube/v3/videos\"\n",
    "        \n",
    "        params = {\n",
    "            \"part\": \"contentDetails\",\n",
    "            \"id\": ids_str,\n",
    "            \"key\": api_key\n",
    "        }\n",
    "\n",
    "        r = requests.get(url, params=params)\n",
    "        if r.status_code !=200:\n",
    "            continue\n",
    "\n",
    "        data = r.json()\n",
    "\n",
    "        for item in data.get(\"items\", []):\n",
    "            vid = item[\"id\"]\n",
    "            iso_dur = item.get(\"contentDetails\", {}).get(\"duration\")\n",
    "            durations[vid] = parse_iso8601_duration_to_seconds(iso_dur)\n",
    "\n",
    "    return durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd81d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# les YouTube Shorts étant limités à 3 minutes max, on limite l'extraction des vidéos à celles faisant au moins 3:01\n",
    "\n",
    "def get_last_50_long_videos(playlist_id, api_key, min_duration=181, max_pages=10):\n",
    "\n",
    "    collected = []\n",
    "    page_token = None\n",
    "    pages = 0\n",
    "\n",
    "    while len(collected) < 50 and pages < max_pages:\n",
    "\n",
    "        params = {\n",
    "            \"part\": \"snippet\",\n",
    "            \"playlistId\": playlist_id,\n",
    "            \"maxResults\": 50,\n",
    "            \"key\": api_key\n",
    "        }\n",
    "\n",
    "        if page_token:\n",
    "            params[\"pageToken\"] = page_token\n",
    "\n",
    "        r = requests.get(\"https://www.googleapis.com/youtube/v3/playlistItems\", params=params)\n",
    "        if r.status_code !=200:\n",
    "            break\n",
    "\n",
    "        data = r.json()\n",
    "\n",
    "        items = data.get(\"items\", [])\n",
    "        if not items:\n",
    "            break\n",
    "\n",
    "        video_ids = [\n",
    "            it[\"snippet\"][\"resourceId\"][\"videoId\"] for it in items\n",
    "        ]\n",
    "    \n",
    "        durations = get_durations_from_videos(video_ids, api_key)\n",
    "\n",
    "        for it in items:\n",
    "            vid = it[\"snippet\"][\"resourceId\"][\"videoId\"]\n",
    "            if durations.get(vid, 0) >= min_duration:\n",
    "                collected.append(vid)\n",
    "                if len(collected) == 50:\n",
    "                    break\n",
    "\n",
    "        page_token = data.get(\"nextPageToken\")\n",
    "        if not page_token:\n",
    "            break\n",
    "\n",
    "        pages +=1\n",
    "\n",
    "    return collected, len(collected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2068bc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_viewcount_from_videos(video_ids, api_key):\n",
    "\n",
    "    views = {}\n",
    "\n",
    "    for i in range(0, len(video_ids), 50):\n",
    "        batch = video_ids[i:i+50]\n",
    "\n",
    "        url = \"https://www.googleapis.com/youtube/v3/videos\"\n",
    "\n",
    "        params = {\n",
    "            \"part\": \"statistics\",\n",
    "            \"id\": \",\".join(batch),\n",
    "            \"key\": api_key\n",
    "        }\n",
    "\n",
    "        r = requests.get(url, params=params)\n",
    "        if r.status_code !=200:\n",
    "            break\n",
    "\n",
    "        data = r.json()\n",
    "\n",
    "        for item in data.get(\"items\", []):\n",
    "            views[item[\"id\"]] = int(item[\"statistics\"].get(\"viewCount\", 0))\n",
    "            \n",
    "    return views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8dc947d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cadence_30j_long_only(playlist_id, api_key, min_duration=181, max_pages=50):\n",
    "    cutoff = datetime.datetime.utcnow().replace(tzinfo=datetime.timezone.utc) - datetime.timedelta(days=30)\n",
    "\n",
    "    count = 0\n",
    "    next_token = None\n",
    "    pages = 0\n",
    "\n",
    "    while pages < max_pages:\n",
    "        # 1) Page d'IDs (triée du plus récent au plus ancien)\n",
    "        params = {\n",
    "            \"part\": \"snippet,contentDetails\",\n",
    "            \"playlistId\": playlist_id,\n",
    "            \"maxResults\": 50,\n",
    "            \"key\": api_key\n",
    "        }\n",
    "        if next_token:\n",
    "            params[\"pageToken\"] = next_token\n",
    "\n",
    "        r = requests.get(\"https://www.googleapis.com/youtube/v3/playlistItems\", params=params)\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "        items = data.get(\"items\", [])\n",
    "        if not items:\n",
    "            break\n",
    "\n",
    "        video_ids = [it[\"contentDetails\"][\"videoId\"] for it in items]\n",
    "\n",
    "        # 2) Détails canonique (date + durée) sur ces IDs\n",
    "        r2 = requests.get(\n",
    "            \"https://www.googleapis.com/youtube/v3/videos\",\n",
    "            params={\"part\": \"snippet,contentDetails\", \"id\": \",\".join(video_ids), \"key\": api_key}\n",
    "        )\n",
    "        r2.raise_for_status()\n",
    "        vdata = r2.json()\n",
    "\n",
    "        for v in vdata.get(\"items\", []):\n",
    "            published = datetime.datetime.fromisoformat(v[\"snippet\"][\"publishedAt\"].replace(\"Z\", \"+00:00\"))\n",
    "            if published >= cutoff:\n",
    "                duration_iso = v.get(\"contentDetails\", {}).get(\"duration\")\n",
    "                if not duration_iso:\n",
    "                    continue\n",
    "                \n",
    "                dur = parse_iso8601_duration_to_seconds(duration_iso)\n",
    "                if dur >= min_duration:\n",
    "                    count += 1\n",
    "\n",
    "        # arrêt propre : si le PLUS ANCIEN item de la page est déjà < cutoff, tout le reste sera plus ancien\n",
    "        oldest_in_page = datetime.datetime.fromisoformat(items[-1][\"snippet\"][\"publishedAt\"].replace(\"Z\", \"+00:00\"))\n",
    "        if oldest_in_page < cutoff:\n",
    "            break\n",
    "\n",
    "        next_token = data.get(\"nextPageToken\")\n",
    "        if not next_token:\n",
    "            break\n",
    "\n",
    "        pages += 1\n",
    "\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23456f69",
   "metadata": {},
   "source": [
    "## 3. Boucle finale avec les indicateurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63fe8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timba\\AppData\\Local\\Temp\\ipykernel_29396\\976357128.py:2: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  cutoff = datetime.datetime.utcnow().replace(tzinfo=datetime.timezone.utc) - datetime.timedelta(days=30)\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for _, row in df_channels.iterrows():\n",
    "\n",
    "    channel_id = row[\"channel_id\"]\n",
    "    subscribers = row[\"subscribers\"]\n",
    "    label_name = row[\"label_name\"]\n",
    "\n",
    "    playlist_id = get_uploads_playlist_id(channel_id, api_key)\n",
    "    if playlist_id is None:\n",
    "        continue\n",
    "\n",
    "    video_ids = get_last_50_long_videos(\n",
    "        playlist_id,\n",
    "        api_key,\n",
    "        min_duration=181\n",
    "    )\n",
    "\n",
    "    if not video_ids:\n",
    "        continue\n",
    "\n",
    "    views_dict = get_viewcount_from_videos(video_ids, api_key)\n",
    "    views_list = [\n",
    "        views_dict[v] \n",
    "        for v in video_ids \n",
    "        if v in views_dict\n",
    "    ]\n",
    "    \n",
    "\n",
    "    mediane_vues = statistics.median(views_list) if views_list else None\n",
    "    ratio_vues_abonnes = mediane_vues / subscribers if mediane_vues is not None and subscribers > 0 else None\n",
    "    ecart_type = statistics.stdev(views_list) if len(views_list) >= 2 else None\n",
    "    coherence_relative = ecart_type / mediane_vues if ecart_type and mediane_vues else None\n",
    "    cadence_30j = get_cadence_30j_long_only(playlist_id, api_key, min_duration=181)\n",
    "    \n",
    "\n",
    "    results.append({\n",
    "        \"Nom_du_media\": label_name,\n",
    "        \"mediane_vues\": mediane_vues,\n",
    "        \"ratio_vues_abonnes\": ratio_vues_abonnes,\n",
    "        \"cadence_30j\": cadence_30j,\n",
    "        \"ecart_type_mediane\": ecart_type,\n",
    "        \"coherence_relative\": coherence_relative,\n",
    "    })\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "df_indicators = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40375088",
   "metadata": {},
   "source": [
    "## 4. Export du dataset final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45bae90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_indicators.to_csv(\"../data/clean/medias_youtube_indicateurs_pointvirgule.csv\", sep=\";\", encoding=\"utf-8-sig\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712ba635",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_indicators.to_csv(\"./data/clean/medias_youtube_indicateurs_virgule.csv\", sep=\",\", encoding=\"utf-8-sig\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
